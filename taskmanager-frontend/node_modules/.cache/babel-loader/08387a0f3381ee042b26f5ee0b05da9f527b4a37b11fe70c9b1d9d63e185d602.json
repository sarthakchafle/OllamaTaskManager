{"ast":null,"code":"var _jsxFileName = \"D:\\\\taskmanager-frontend\\\\src\\\\LlmChat.jsx\",\n  _s = $RefreshSig$();\nimport React, { useState } from \"react\";\nimport { jsxDEV as _jsxDEV } from \"react/jsx-dev-runtime\";\nfunction LlmChat() {\n  _s();\n  const [prompt, setPrompt] = useState(\"\");\n  const [response, setResponse] = useState(\"\"); // This holds the extracted LLM response\n  const [isLoading, setIsLoading] = useState(false);\n  const [error, setError] = useState(null);\n  const handlePromptSubmit = async () => {\n    // ... (your existing fetch logic) ...\n    try {\n      const backendUrl = \"http://localhost:8080/api/ask\"; // Make sure this is 'api/ask' now\n      const res = await fetch(backendUrl, {\n        method: \"POST\",\n        headers: {\n          \"Content-Type\": \"application/json\"\n        },\n        body: JSON.stringify({\n          prompt: prompt\n        })\n      });\n      if (!res.ok) {\n        const errorData = await res.json();\n        throw new Error(errorData.message || `HTTP error! Status: ${res.status}`);\n      }\n      const data = await res.json();\n      setResponse(data.response); // This correctly extracts just the 'response' field\n      setPrompt(\"\");\n    } catch (err) {\n      console.error(\"Failed to fetch LLM response:\", err);\n      setError(err.message || \"An unknown error occurred.\");\n    } finally {\n      setIsLoading(false);\n    }\n  };\n\n  // YOU NEED TO FIND THIS 'return' STATEMENT IN YOUR LLMChat.js FILE\n  return /*#__PURE__*/_jsxDEV(\"div\", {\n    style: {\n      padding: \"20px\",\n      maxWidth: \"800px\",\n      margin: \"auto\",\n      fontFamily: \"Arial, sans-serif\"\n    },\n    children: [/*#__PURE__*/_jsxDEV(\"h1\", {\n      children: \"Agentic AI Chat\"\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 45,\n      columnNumber: 7\n    }, this), /*#__PURE__*/_jsxDEV(\"textarea\", {\n      placeholder: \"Enter your prompt here...\",\n      value: prompt,\n      onChange: e => setPrompt(e.target.value),\n      rows: \"5\",\n      style: {\n        width: \"100%\",\n        padding: \"10px\",\n        marginBottom: \"10px\",\n        border: \"1px solid #ccc\"\n      }\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 46,\n      columnNumber: 7\n    }, this), /*#__PURE__*/_jsxDEV(\"button\", {\n      onClick: handlePromptSubmit,\n      disabled: isLoading || !prompt.trim(),\n      style: {\n        padding: \"10px 20px\",\n        backgroundColor: \"#007bff\",\n        color: \"white\",\n        border: \"none\",\n        borderRadius: \"4px\",\n        cursor: \"pointer\",\n        opacity: isLoading || !prompt.trim() ? 0.6 : 1\n      },\n      children: isLoading ? \"Sending...\" : \"Send Prompt\"\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 58,\n      columnNumber: 7\n    }, this), error && /*#__PURE__*/_jsxDEV(\"div\", {\n      style: {\n        color: \"red\",\n        marginTop: \"15px\",\n        border: \"1px solid red\",\n        padding: \"10px\",\n        borderRadius: \"4px\"\n      },\n      children: [\"Error: \", error]\n    }, void 0, true, {\n      fileName: _jsxFileName,\n      lineNumber: 75,\n      columnNumber: 9\n    }, this), response &&\n    /*#__PURE__*/\n    // This checks if the 'response' state variable has any content\n    _jsxDEV(\"div\", {\n      style: {\n        marginTop: \"20px\",\n        padding: \"15px\",\n        border: \"1px solid #ddd\",\n        borderRadius: \"4px\",\n        backgroundColor: \"#f9f9f9\"\n      },\n      children: [/*#__PURE__*/_jsxDEV(\"h2\", {\n        children: \"LLM Response:\"\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 99,\n        columnNumber: 11\n      }, this), /*#__PURE__*/_jsxDEV(\"p\", {\n        children: response\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 100,\n        columnNumber: 11\n      }, this), \" \"]\n    }, void 0, true, {\n      fileName: _jsxFileName,\n      lineNumber: 90,\n      columnNumber: 9\n    }, this)]\n  }, void 0, true, {\n    fileName: _jsxFileName,\n    lineNumber: 37,\n    columnNumber: 5\n  }, this);\n}\n_s(LlmChat, \"vLe7w3N5bLep+ZP3p1zkV5e/BYI=\");\n_c = LlmChat;\nexport default LlmChat;\nvar _c;\n$RefreshReg$(_c, \"LlmChat\");","map":{"version":3,"names":["React","useState","jsxDEV","_jsxDEV","LlmChat","_s","prompt","setPrompt","response","setResponse","isLoading","setIsLoading","error","setError","handlePromptSubmit","backendUrl","res","fetch","method","headers","body","JSON","stringify","ok","errorData","json","Error","message","status","data","err","console","style","padding","maxWidth","margin","fontFamily","children","fileName","_jsxFileName","lineNumber","columnNumber","placeholder","value","onChange","e","target","rows","width","marginBottom","border","onClick","disabled","trim","backgroundColor","color","borderRadius","cursor","opacity","marginTop","_c","$RefreshReg$"],"sources":["D:/taskmanager-frontend/src/LlmChat.jsx"],"sourcesContent":["import React, { useState } from \"react\";\r\n\r\nfunction LlmChat() {\r\n  const [prompt, setPrompt] = useState(\"\");\r\n  const [response, setResponse] = useState(\"\"); // This holds the extracted LLM response\r\n  const [isLoading, setIsLoading] = useState(false);\r\n  const [error, setError] = useState(null);\r\n\r\n  const handlePromptSubmit = async () => {\r\n    // ... (your existing fetch logic) ...\r\n    try {\r\n      const backendUrl = \"http://localhost:8080/api/ask\"; // Make sure this is 'api/ask' now\r\n      const res = await fetch(backendUrl, {\r\n        method: \"POST\",\r\n        headers: { \"Content-Type\": \"application/json\" },\r\n        body: JSON.stringify({ prompt: prompt }),\r\n      });\r\n      if (!res.ok) {\r\n        const errorData = await res.json();\r\n        throw new Error(\r\n          errorData.message || `HTTP error! Status: ${res.status}`\r\n        );\r\n      }\r\n      const data = await res.json();\r\n      setResponse(data.response); // This correctly extracts just the 'response' field\r\n      setPrompt(\"\");\r\n    } catch (err) {\r\n      console.error(\"Failed to fetch LLM response:\", err);\r\n      setError(err.message || \"An unknown error occurred.\");\r\n    } finally {\r\n      setIsLoading(false);\r\n    }\r\n  };\r\n\r\n  // YOU NEED TO FIND THIS 'return' STATEMENT IN YOUR LLMChat.js FILE\r\n  return (\r\n    <div\r\n      style={{\r\n        padding: \"20px\",\r\n        maxWidth: \"800px\",\r\n        margin: \"auto\",\r\n        fontFamily: \"Arial, sans-serif\",\r\n      }}\r\n    >\r\n      <h1>Agentic AI Chat</h1>\r\n      <textarea\r\n        placeholder=\"Enter your prompt here...\"\r\n        value={prompt}\r\n        onChange={(e) => setPrompt(e.target.value)}\r\n        rows=\"5\"\r\n        style={{\r\n          width: \"100%\",\r\n          padding: \"10px\",\r\n          marginBottom: \"10px\",\r\n          border: \"1px solid #ccc\",\r\n        }}\r\n      />\r\n      <button\r\n        onClick={handlePromptSubmit}\r\n        disabled={isLoading || !prompt.trim()}\r\n        style={{\r\n          padding: \"10px 20px\",\r\n          backgroundColor: \"#007bff\",\r\n          color: \"white\",\r\n          border: \"none\",\r\n          borderRadius: \"4px\",\r\n          cursor: \"pointer\",\r\n          opacity: isLoading || !prompt.trim() ? 0.6 : 1,\r\n        }}\r\n      >\r\n        {isLoading ? \"Sending...\" : \"Send Prompt\"}\r\n      </button>\r\n\r\n      {error && (\r\n        <div\r\n          style={{\r\n            color: \"red\",\r\n            marginTop: \"15px\",\r\n            border: \"1px solid red\",\r\n            padding: \"10px\",\r\n            borderRadius: \"4px\",\r\n          }}\r\n        >\r\n          Error: {error}\r\n        </div>\r\n      )}\r\n\r\n      {/* THIS IS THE PART YOU NEED TO CONFIRM IN YOUR CODE */}\r\n      {response && ( // This checks if the 'response' state variable has any content\r\n        <div\r\n          style={{\r\n            marginTop: \"20px\",\r\n            padding: \"15px\",\r\n            border: \"1px solid #ddd\",\r\n            borderRadius: \"4px\",\r\n            backgroundColor: \"#f9f9f9\",\r\n          }}\r\n        >\r\n          <h2>LLM Response:</h2>\r\n          <p>{response}</p>{\" \"}\r\n          {/* <--- THIS IS WHERE THE 'response' STATE IS RENDERED */}\r\n        </div>\r\n      )}\r\n      {/* END OF THE PART TO CONFIRM */}\r\n    </div>\r\n  );\r\n}\r\n\r\nexport default LlmChat;\r\n"],"mappings":";;AAAA,OAAOA,KAAK,IAAIC,QAAQ,QAAQ,OAAO;AAAC,SAAAC,MAAA,IAAAC,OAAA;AAExC,SAASC,OAAOA,CAAA,EAAG;EAAAC,EAAA;EACjB,MAAM,CAACC,MAAM,EAAEC,SAAS,CAAC,GAAGN,QAAQ,CAAC,EAAE,CAAC;EACxC,MAAM,CAACO,QAAQ,EAAEC,WAAW,CAAC,GAAGR,QAAQ,CAAC,EAAE,CAAC,CAAC,CAAC;EAC9C,MAAM,CAACS,SAAS,EAAEC,YAAY,CAAC,GAAGV,QAAQ,CAAC,KAAK,CAAC;EACjD,MAAM,CAACW,KAAK,EAAEC,QAAQ,CAAC,GAAGZ,QAAQ,CAAC,IAAI,CAAC;EAExC,MAAMa,kBAAkB,GAAG,MAAAA,CAAA,KAAY;IACrC;IACA,IAAI;MACF,MAAMC,UAAU,GAAG,+BAA+B,CAAC,CAAC;MACpD,MAAMC,GAAG,GAAG,MAAMC,KAAK,CAACF,UAAU,EAAE;QAClCG,MAAM,EAAE,MAAM;QACdC,OAAO,EAAE;UAAE,cAAc,EAAE;QAAmB,CAAC;QAC/CC,IAAI,EAAEC,IAAI,CAACC,SAAS,CAAC;UAAEhB,MAAM,EAAEA;QAAO,CAAC;MACzC,CAAC,CAAC;MACF,IAAI,CAACU,GAAG,CAACO,EAAE,EAAE;QACX,MAAMC,SAAS,GAAG,MAAMR,GAAG,CAACS,IAAI,CAAC,CAAC;QAClC,MAAM,IAAIC,KAAK,CACbF,SAAS,CAACG,OAAO,IAAI,uBAAuBX,GAAG,CAACY,MAAM,EACxD,CAAC;MACH;MACA,MAAMC,IAAI,GAAG,MAAMb,GAAG,CAACS,IAAI,CAAC,CAAC;MAC7BhB,WAAW,CAACoB,IAAI,CAACrB,QAAQ,CAAC,CAAC,CAAC;MAC5BD,SAAS,CAAC,EAAE,CAAC;IACf,CAAC,CAAC,OAAOuB,GAAG,EAAE;MACZC,OAAO,CAACnB,KAAK,CAAC,+BAA+B,EAAEkB,GAAG,CAAC;MACnDjB,QAAQ,CAACiB,GAAG,CAACH,OAAO,IAAI,4BAA4B,CAAC;IACvD,CAAC,SAAS;MACRhB,YAAY,CAAC,KAAK,CAAC;IACrB;EACF,CAAC;;EAED;EACA,oBACER,OAAA;IACE6B,KAAK,EAAE;MACLC,OAAO,EAAE,MAAM;MACfC,QAAQ,EAAE,OAAO;MACjBC,MAAM,EAAE,MAAM;MACdC,UAAU,EAAE;IACd,CAAE;IAAAC,QAAA,gBAEFlC,OAAA;MAAAkC,QAAA,EAAI;IAAe;MAAAC,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OAAI,CAAC,eACxBtC,OAAA;MACEuC,WAAW,EAAC,2BAA2B;MACvCC,KAAK,EAAErC,MAAO;MACdsC,QAAQ,EAAGC,CAAC,IAAKtC,SAAS,CAACsC,CAAC,CAACC,MAAM,CAACH,KAAK,CAAE;MAC3CI,IAAI,EAAC,GAAG;MACRf,KAAK,EAAE;QACLgB,KAAK,EAAE,MAAM;QACbf,OAAO,EAAE,MAAM;QACfgB,YAAY,EAAE,MAAM;QACpBC,MAAM,EAAE;MACV;IAAE;MAAAZ,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OACH,CAAC,eACFtC,OAAA;MACEgD,OAAO,EAAErC,kBAAmB;MAC5BsC,QAAQ,EAAE1C,SAAS,IAAI,CAACJ,MAAM,CAAC+C,IAAI,CAAC,CAAE;MACtCrB,KAAK,EAAE;QACLC,OAAO,EAAE,WAAW;QACpBqB,eAAe,EAAE,SAAS;QAC1BC,KAAK,EAAE,OAAO;QACdL,MAAM,EAAE,MAAM;QACdM,YAAY,EAAE,KAAK;QACnBC,MAAM,EAAE,SAAS;QACjBC,OAAO,EAAEhD,SAAS,IAAI,CAACJ,MAAM,CAAC+C,IAAI,CAAC,CAAC,GAAG,GAAG,GAAG;MAC/C,CAAE;MAAAhB,QAAA,EAED3B,SAAS,GAAG,YAAY,GAAG;IAAa;MAAA4B,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OACnC,CAAC,EAER7B,KAAK,iBACJT,OAAA;MACE6B,KAAK,EAAE;QACLuB,KAAK,EAAE,KAAK;QACZI,SAAS,EAAE,MAAM;QACjBT,MAAM,EAAE,eAAe;QACvBjB,OAAO,EAAE,MAAM;QACfuB,YAAY,EAAE;MAChB,CAAE;MAAAnB,QAAA,GACH,SACQ,EAACzB,KAAK;IAAA;MAAA0B,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OACV,CACN,EAGAjC,QAAQ;IAAA;IAAM;IACbL,OAAA;MACE6B,KAAK,EAAE;QACL2B,SAAS,EAAE,MAAM;QACjB1B,OAAO,EAAE,MAAM;QACfiB,MAAM,EAAE,gBAAgB;QACxBM,YAAY,EAAE,KAAK;QACnBF,eAAe,EAAE;MACnB,CAAE;MAAAjB,QAAA,gBAEFlC,OAAA;QAAAkC,QAAA,EAAI;MAAa;QAAAC,QAAA,EAAAC,YAAA;QAAAC,UAAA;QAAAC,YAAA;MAAA,OAAI,CAAC,eACtBtC,OAAA;QAAAkC,QAAA,EAAI7B;MAAQ;QAAA8B,QAAA,EAAAC,YAAA;QAAAC,UAAA;QAAAC,YAAA;MAAA,OAAI,CAAC,EAAC,GAAG;IAAA;MAAAH,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OAElB,CACN;EAAA;IAAAH,QAAA,EAAAC,YAAA;IAAAC,UAAA;IAAAC,YAAA;EAAA,OAEE,CAAC;AAEV;AAACpC,EAAA,CAxGQD,OAAO;AAAAwD,EAAA,GAAPxD,OAAO;AA0GhB,eAAeA,OAAO;AAAC,IAAAwD,EAAA;AAAAC,YAAA,CAAAD,EAAA","ignoreList":[]},"metadata":{},"sourceType":"module","externalDependencies":[]}